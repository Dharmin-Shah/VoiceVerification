{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Voice Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPcCjNyLpqCOPZ2wwn6gw3U",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dharmin-Shah/Voice_Recognition/blob/main/Voice_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvVmiPInueiW"
      },
      "source": [
        "#**Voice Recognition Project**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HZmLwjJu0Qv"
      },
      "source": [
        "### **Introduction**\n",
        "\n",
        "In the following project, we are trying to recognize the speaker based on the audio file provided.<br>\n",
        "\n",
        "> For this particular project I have used the [pyAudioAnalysis](https://github.com/tyiannak/pyAudioAnalysis) repo. It has a detailed explanation on how feature extraction can be performed and has many functions that can be used to achieve our goal.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoMRC6vYw7JE"
      },
      "source": [
        "### **Preprocessing**\n",
        "\n",
        "\n",
        "> We need to import the libraries to be used, download and install the repo and fetch, download and extract the dataset to be used.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYksgzrOxYdZ"
      },
      "source": [
        " > Imports include basic python libs and machine learning (sklearn)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6UwiVS5QXSy"
      },
      "source": [
        "import os\n",
        "import random\n",
        "import shutil"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sM3UiPgPIIuY"
      },
      "source": [
        "import joblib\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9vXO0bhhI0h"
      },
      "source": [
        "import sqlite3\n",
        "import datetime\n",
        "from google.colab import files"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35xKBJhzJ13v"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2eZVelux6Jk"
      },
      "source": [
        "\n",
        "\n",
        "> Installing the repo pyAudioAnalysis\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvyZoGoFQdQA"
      },
      "source": [
        "def repo_fetch_clean_install():\n",
        "  '''\n",
        "  In this function we fetch the github repo of pyAudioAnalysis and perform\n",
        "  some clean up \n",
        "  '''\n",
        "  # Remove any previous installation of pyAudioAnalysis\n",
        "  os.system(\"rm -rf pyAudioAnalysis/\")\n",
        "\n",
        "  # Fetch the pyAudioAnalysis repo\n",
        "  os.system(\"git clone https://github.com/tyiannak/pyAudioAnalysis.git\")\n",
        "\n",
        "  os.system(\"mv pyAudioAnalysis/pyAudioAnalysis/* pyAudioAnalysis/\")\n",
        "  os.system(\"rmdir pyAudioAnalysis/pyAudioAnalysis/\")\n",
        "\n",
        "  # Updating requirements.txt to install the latest libraries\n",
        "  dep = []\n",
        "  with open('pyAudioAnalysis/requirements.txt','r') as f:\n",
        "    dep = f.readlines()\n",
        "    dep = [lib.split('==')[0] for lib in dep]\n",
        "    print(dep) \n",
        "  f.close()\n",
        "\n",
        "  # Writing the new requirements\n",
        "  with open('pyAudioAnalysis/requirements.txt','w') as f:\n",
        "    f.write('\\n'.join(dep))\n",
        "  f.close()\n",
        "\n",
        "  os.system(\"pip install -r pyAudioAnalysis/requirements.txt\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jUMExQORMsm",
        "outputId": "b0995d8d-23ee-4568-8ecb-cd7053adf681"
      },
      "source": [
        "repo_fetch_clean_install()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['matplotlib', 'simplejson', 'scipy', 'numpy', 'hmmlearn', 'eyeD3', 'pydub', 'scikit_learn', 'tqdm', 'plotly', '\\n']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tET2OzIoSbSx"
      },
      "source": [
        "> Once the repo is installed, import required libraries from it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gu1K2KdYO-F4"
      },
      "source": [
        "from pyAudioAnalysis import MidTermFeatures as aT\n",
        "from pyAudioAnalysis import audioBasicIO"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyhLokNOyf4c"
      },
      "source": [
        "\n",
        "\n",
        "> Fetching, downloading and extracting the dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilUfr0do9kpn"
      },
      "source": [
        "> Before this function is called, it is important to refer to the following link [Kaggle API](https://github.com/Kaggle/kaggle-api#api-credentials) to get the kaggle.json file. Once the file has been downloaded, the process can continue."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lL_LxVtRQhv"
      },
      "source": [
        "def kaggle_dataset_fetch(kgdata):\n",
        "  '''\n",
        "  This function will dowanload and unzip the required dataset.\n",
        "  Initial lines of code are necessary to install the kaggle api and use the\n",
        "  kaggle.json file to link the dataset.\n",
        "\n",
        "  ARGS: Kaggle dataset name that needs to be downloaded. This can be obtained by \n",
        "         using the 'Copy API Command' from dataset's page. The last argument in the\n",
        "         command is the dataset name.\n",
        "  '''\n",
        "\n",
        "  #Installing kaggle api\n",
        "  os.system(\"pip install -q kaggle\")\n",
        "\n",
        "  # Remove any exiting kaggle.json file\n",
        "  #os.system(\"rm -f kaggle.json\")\n",
        "  \n",
        "  # Cleanup\n",
        "  os.system(\"rm -r -f ~/.kaggle/\")\n",
        "  os.system(\"mkdir ~/.kaggle/\")\n",
        "  \n",
        "  # Uploading the kaggle.json file\n",
        "  uploaded = files.upload()\n",
        "  \n",
        "  if uploaded.get(\"kaggle.json\") == None:\n",
        "    raise Exception(\"kaggle.json was not found. Please upload again\")\n",
        "  \n",
        "  # Granting permissions\n",
        "  os.system(\"cp kaggle.json ~/.kaggle/\")\n",
        "  os.system(\"chmod 600 /root/.kaggle/kaggle.json\")\n",
        "\n",
        "  #Download voice dataset for testing\n",
        "  os.system(f\"kaggle datasets download -d {kgdata}\")\n",
        "\n",
        "  #Unzipping the dataset\n",
        "  z = os.popen(\"ls *.zip\").read()\n",
        "  os.system(f\"unzip {z}\")\n",
        "  \n",
        "  #Removing zip file once we unzip it\n",
        "  os.system(f\"rm -f {z}\")"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kx-SIyLTpBz",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "8607d2ab-c369-4679-b839-d7f56ce77814"
      },
      "source": [
        "kaggle_dataset_fetch(\"vjcalling/speaker-recognition-audio-dataset\")"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-55be548f-07cb-462f-9e92-f7ac0d21cac2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-55be548f-07cb-462f-9e92-f7ac0d21cac2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ydlGirLyn7R"
      },
      "source": [
        "### Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EmFCWx_yzmB"
      },
      "source": [
        "\n",
        "\n",
        ">For the purpose of running this project, we are taking a small dataset from the 50 Speakers available.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VE0IPlvDdqmM"
      },
      "source": [
        "  # Selecting the data\n",
        "  x=['Speaker_0005','Speaker_0014','Speaker_0021','Speaker0035','Speaker0042',\n",
        "     'Speaker0029','Speaker0037']\n",
        "  # Main directory where all data is present\n",
        "  ma_dir = \"50_speakers_audio_data\"\n",
        "  # Target directory to get the train, test split for the data\n",
        "  tr_dir = \"speaker_data\""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nb0RH-UzGDS"
      },
      "source": [
        "\n",
        "\n",
        "> Creation of train, test folders and selecting the files for test data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDI0wzKjXt9z"
      },
      "source": [
        "def prepare_train_test(data,ma_dir,tr_dir,test=0.3):\n",
        "  \n",
        "  '''\n",
        "  This function will prepare the train, test folders and copy the data required for\n",
        "  our experiment.\n",
        "\n",
        "  ARGS:\n",
        "    - data:   The data for which the train,test data needs to be prepared\n",
        "    - ma_dir: The unzipped dataset that has all the data\n",
        "    - tr_dir: The target directory under which the train and test folder need to be\n",
        "              created.\n",
        "    - test:   The size of test data to be generated per folder\n",
        "  '''\n",
        "\n",
        "\n",
        "  # Creating the directory for the train and test data and copying subdirectories to train data\n",
        "  for i in data:\n",
        "    # Copy the wavefiles with structure\n",
        "    shutil.copytree(f\"{ma_dir}/{i}\",f\"{tr_dir}/train_data/wavfiles/{i}\")\n",
        "    # Copy the structre only for feature extraction\n",
        "    shutil.copytree(f\"{ma_dir}/{i}\",f\"{tr_dir}/train_data/features/{i}\",ignore=shutil.ignore_patterns('*.*'))\n",
        "    # Copy the structure for test data\n",
        "    shutil.copytree(f\"{ma_dir}/{i}\",f\"{tr_dir}/test_data/{i}\",ignore=shutil.ignore_patterns('*.*'))\n",
        "  \n",
        "  # Randomly choosing files from train data to move them to test data\n",
        "  for speaker in os.listdir(f\"{tr_dir}/train_data/wavfiles\"):\n",
        "    pop = os.listdir(f\"{tr_dir}/train_data/wavfiles/{speaker}\")\n",
        "    test_size = len(pop) * test\n",
        "    random.shuffle(pop)\n",
        "    test_data = pop[-int(test_size):]\n",
        "    \n",
        "    # Moving the test data to test folder\n",
        "    for f in test_data:\n",
        "      shutil.move(f\"{tr_dir}/train_data/wavfiles/{speaker}/{f}\",f\"{tr_dir}/test_data/{speaker}\")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_jyVTr-gPjo"
      },
      "source": [
        "prepare_train_test(x,ma_dir,tr_dir)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKLbwSaazpvp"
      },
      "source": [
        "\n",
        "\n",
        "> In this section, we use the pyAudioAnalysis' function to perform feature extraction for each of the files present in each of the speakers.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NMc0P9S0EEq"
      },
      "source": [
        "\n",
        "\n",
        "> Features extracted through the process are 136. For further explaination on how these are selected please [read here\n",
        "](https://hackernoon.com/intro-to-audio-analysis-recognizing-sounds-using-machine-learning-qy2r3ufl)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EhIX4yB0-9L"
      },
      "source": [
        "> The features once extracted are then stored in indivual pickle files for furture use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdzsslvQmwT2"
      },
      "source": [
        "def analyze_store_wav(tr_dir,mid_window=1,mid_step=1,\n",
        "                      short_window=0.05,short_step=0.05):\n",
        "    '''\n",
        "    This function performs featrue extraction using pyAudioAnalysis repo and stores\n",
        "    the features into indivual pickle files for each wavefile\n",
        "\n",
        "    ARGS:\n",
        "      tr_dir:       Target directory under which train,test folders are created\n",
        "      mid_window:   Mid-term window\n",
        "      mid_step:     Mid-term step\n",
        "      short_window: Short-term window\n",
        "      short_step:   Short-term step\n",
        "\n",
        "    '''\n",
        "    for lbl in os.listdir(f\"{tr_dir}/train_data/wavfiles\"):\n",
        "      path = f\"{tr_dir}/train_data/wavfiles/{lbl}\"\n",
        "      print(lbl)\n",
        "      # Getting the features for each file present in the directory.\n",
        "      fn,f,mn = aT.directory_feature_extraction(path,mid_window,mid_step,short_window,short_step,compute_beat=False)\n",
        "\n",
        "      #Writing extracted features to pickle file\n",
        "      for i in range(len(fn)):  \n",
        "        f[i] = f[i].split('/')[-1][:-4]\n",
        "        path = path.replace(\"wavfiles\",\"features\")\n",
        "        joblib.dump((fn[i],lbl),f\"{path}/{f[i]}.pkl\")\n",
        "        "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgI45uApkCs3",
        "outputId": "a93f5f29-bd05-4f6b-a72e-0c0410deb3b0"
      },
      "source": [
        "analyze_store_wav(tr_dir,mid_window=1,mid_step=1,short_window=0.05,short_step=0.05)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Speaker_0005\n",
            "Analyzing file 1 of 51: speaker_data/train_data/wavfiles/Speaker_0005/Speaker_0005_00001.wav\n",
            "Analyzing file 2 of 51: speaker_data/train_data/wavfiles/Speaker_0005/Speaker_0005_00002.wav\n",
            "Analyzing file 3 of 51: speaker_data/train_data/wavfiles/Speaker_0005/Speaker_0005_00003.wav\n",
            "Analyzing file 4 of 51: speaker_data/train_data/wavfiles/Speaker_0005/Speaker_0005_00004.wav\n",
            "Analyzing file 5 of 51: speaker_data/train_data/wavfiles/Speaker_0005/Speaker_0005_00006.wav\n",
            "Analyzing file 6 of 51: speaker_data/train_data/wavfiles/Speaker_0005/Speaker_0005_00009.wav\n",
            "Analyzing file 7 of 51: speaker_data/train_data/wavfiles/Speaker_0005/Speaker_0005_00010.wav\n",
            "Analyzing file 8 of 51: speaker_data/train_data/wavfiles/Speaker_0005/Speaker_0005_00011.wav\n",
            "Analyzing file 9 of 51: speaker_data/train_data/wavfiles/Speaker_0005/Speaker_0005_00013.wav\n",
            "Analyzing file 10 of 51: speaker_data/train_data/wavfiles/Speaker_0005/Speaker_0005_00014.wav\n",
            "Analyzing file 11 of 51: speaker_data/train_data/wavfiles/Speaker_0005/Speaker_0005_00015.wav\n",
            "Analyzing file 12 of 51: speaker_data/train_data/wavfiles/Speaker_0005/Speaker_0005_00016.wav\n",
            "Analyzing file 13 of 51: speaker_data/train_data/wavfiles/Speaker_0005/Speaker_0005_00017.wav\n",
            "Analyzing file 14 of 51: speaker_data/train_data/wavfiles/Speaker_0005/Speaker_0005_00018.wav\n",
            "Analyzing file 15 of 51: speaker_data/train_data/wavfiles/Speaker_0005/Speaker_0005_00020.wav\n",
            "Analyzing file 16 of 51: speaker_data/train_data/wavfiles/Speaker_0005/Speaker_0005_00021.wav\n",
            "Analyzing file 17 of 51: speaker_data/train_data/wavfiles/Speaker_0005/Speaker_0005_00022.wav\n",
            "Analyzing file 18 of 51: speaker_data/train_data/wavfiles/Speaker_0005/Speaker_0005_00023.wav\n",
            "Analyzing file 19 of 51: speaker_data/train_data/wavfiles/Speaker_0005/Speaker_0005_00024.wav\n",
            "Analyzing file 20 of 51: speaker_data/train_data/wavfiles/Speaker_0005/Speaker_0005_00026.wav\n",
            "Analyzing file 21 of 51: speaker_data/train_data/wavfiles/Speaker_0005/Speaker_0005_00027.wav\n",
            "Analyzing file 22 of 51: speaker_data/train_data/wavfiles/Speaker_0005/Speaker_0005_00028.wav\n",
            "Analyzing file 23 of 51: speaker_data/train_data/wavfiles/Speaker_0005/Speaker_0005_00029.wav\n",
            "Analyzing file 24 of 51: speaker_data/train_data/wavfiles/Speaker_0005/Speaker_0005_00030.wav\n",
            "Analyzing file 25 of 51: speaker_data/train_data/wavfiles/Speaker_0005/Speaker_0005_00031.wav\n",
            "Analyzing file 26 of 51: speaker_data/train_data/wavfiles/Speaker_0005/Speaker_0005_00032.wav\n",
            "Analyzing file 27 of 51: speaker_data/train_data/wavfiles/Speaker_0005/Speaker_0005_00033.wav\n",
            "Analyzing file 28 of 51: speaker_data/train_data/wavfiles/Speaker_0005/Speaker_0005_00034.wav\n",
            "Analyzing file 29 of 51: speaker_data/train_data/wavfiles/Speaker_0005/Speaker_0005_00036.wav\n",
            "Analyzing file 30 of 51: speaker_data/train_data/wavfiles/Speaker_0005/Speaker_0005_00037.wav\n",
            "Analyzing file 31 of 51: speaker_data/train_data/wavfiles/Speaker_0005/Speaker_0005_00038.wav\n",
            "Analyzing file 32 of 51: speaker_data/train_data/wavfiles/Speaker_0005/Speaker_0005_00040.wav\n",
            "Analyzing file 33 of 51: speaker_data/train_data/wavfiles/Speaker_0005/Speaker_0005_00041.wav\n",
            "Analyzing file 34 of 51: speaker_data/train_data/wavfiles/Speaker_0005/Speaker_0005_00042.wav\n",
            "Analyzing file 35 of 51: speaker_data/train_data/wavfiles/Speaker_0005/Speaker_0005_00044.wav\n",
            "Analyzing file 36 of 51: speaker_data/train_data/wavfiles/Speaker_0005/Speaker_0005_00046.wav\n",
            "Analyzing file 37 of 51: speaker_data/train_data/wavfiles/Speaker_0005/Speaker_0005_00048.wav\n",
            "Analyzing file 38 of 51: speaker_data/train_data/wavfiles/Speaker_0005/Speaker_0005_00050.wav\n",
            "Analyzing file 39 of 51: speaker_data/train_data/wavfiles/Speaker_0005/Speaker_0005_00054.wav\n",
            "Analyzing file 40 of 51: speaker_data/train_data/wavfiles/Speaker_0005/Speaker_0005_00055.wav\n",
            "Analyzing file 41 of 51: speaker_data/train_data/wavfiles/Speaker_0005/Speaker_0005_00056.wav\n",
            "Analyzing file 42 of 51: speaker_data/train_data/wavfiles/Speaker_0005/Speaker_0005_00058.wav\n",
            "Analyzing file 43 of 51: speaker_data/train_data/wavfiles/Speaker_0005/Speaker_0005_00060.wav\n",
            "Analyzing file 44 of 51: speaker_data/train_data/wavfiles/Speaker_0005/Speaker_0005_00061.wav\n",
            "Analyzing file 45 of 51: speaker_data/train_data/wavfiles/Speaker_0005/Speaker_0005_00062.wav\n",
            "Analyzing file 46 of 51: speaker_data/train_data/wavfiles/Speaker_0005/Speaker_0005_00064.wav\n",
            "Analyzing file 47 of 51: speaker_data/train_data/wavfiles/Speaker_0005/Speaker_0005_00065.wav\n",
            "Analyzing file 48 of 51: speaker_data/train_data/wavfiles/Speaker_0005/Speaker_0005_00066.wav\n",
            "Analyzing file 49 of 51: speaker_data/train_data/wavfiles/Speaker_0005/Speaker_0005_00067.wav\n",
            "Analyzing file 50 of 51: speaker_data/train_data/wavfiles/Speaker_0005/Speaker_0005_00068.wav\n",
            "Analyzing file 51 of 51: speaker_data/train_data/wavfiles/Speaker_0005/Speaker_0005_00069.wav\n",
            "Feature extraction complexity ratio: 35.4 x realtime\n",
            "Speaker0029\n",
            "Analyzing file 1 of 22: speaker_data/train_data/wavfiles/Speaker0029/Speaker29_000.wav\n",
            "Analyzing file 2 of 22: speaker_data/train_data/wavfiles/Speaker0029/Speaker29_001.wav\n",
            "Analyzing file 3 of 22: speaker_data/train_data/wavfiles/Speaker0029/Speaker29_002.wav\n",
            "Analyzing file 4 of 22: speaker_data/train_data/wavfiles/Speaker0029/Speaker29_004.wav\n",
            "Analyzing file 5 of 22: speaker_data/train_data/wavfiles/Speaker0029/Speaker29_006.wav\n",
            "Analyzing file 6 of 22: speaker_data/train_data/wavfiles/Speaker0029/Speaker29_007.wav\n",
            "Analyzing file 7 of 22: speaker_data/train_data/wavfiles/Speaker0029/Speaker29_009.wav\n",
            "Analyzing file 8 of 22: speaker_data/train_data/wavfiles/Speaker0029/Speaker29_011.wav\n",
            "Analyzing file 9 of 22: speaker_data/train_data/wavfiles/Speaker0029/Speaker29_012.wav\n",
            "Analyzing file 10 of 22: speaker_data/train_data/wavfiles/Speaker0029/Speaker29_013.wav\n",
            "Analyzing file 11 of 22: speaker_data/train_data/wavfiles/Speaker0029/Speaker29_014.wav\n",
            "Analyzing file 12 of 22: speaker_data/train_data/wavfiles/Speaker0029/Speaker29_015.wav\n",
            "Analyzing file 13 of 22: speaker_data/train_data/wavfiles/Speaker0029/Speaker29_016.wav\n",
            "Analyzing file 14 of 22: speaker_data/train_data/wavfiles/Speaker0029/Speaker29_017.wav\n",
            "Analyzing file 15 of 22: speaker_data/train_data/wavfiles/Speaker0029/Speaker29_019.wav\n",
            "Analyzing file 16 of 22: speaker_data/train_data/wavfiles/Speaker0029/Speaker29_020.wav\n",
            "Analyzing file 17 of 22: speaker_data/train_data/wavfiles/Speaker0029/Speaker29_021.wav\n",
            "Analyzing file 18 of 22: speaker_data/train_data/wavfiles/Speaker0029/Speaker29_022.wav\n",
            "Analyzing file 19 of 22: speaker_data/train_data/wavfiles/Speaker0029/Speaker29_023.wav\n",
            "Analyzing file 20 of 22: speaker_data/train_data/wavfiles/Speaker0029/Speaker29_025.wav\n",
            "Analyzing file 21 of 22: speaker_data/train_data/wavfiles/Speaker0029/Speaker29_028.wav\n",
            "Analyzing file 22 of 22: speaker_data/train_data/wavfiles/Speaker0029/Speaker29_029.wav\n",
            "Feature extraction complexity ratio: 31.4 x realtime\n",
            "Speaker_0014\n",
            "Analyzing file 1 of 36: speaker_data/train_data/wavfiles/Speaker_0014/Speaker_0014_00000.wav\n",
            "Analyzing file 2 of 36: speaker_data/train_data/wavfiles/Speaker_0014/Speaker_0014_00001.wav\n",
            "Analyzing file 3 of 36: speaker_data/train_data/wavfiles/Speaker_0014/Speaker_0014_00003.wav\n",
            "Analyzing file 4 of 36: speaker_data/train_data/wavfiles/Speaker_0014/Speaker_0014_00005.wav\n",
            "Analyzing file 5 of 36: speaker_data/train_data/wavfiles/Speaker_0014/Speaker_0014_00006.wav\n",
            "Analyzing file 6 of 36: speaker_data/train_data/wavfiles/Speaker_0014/Speaker_0014_00007.wav\n",
            "Analyzing file 7 of 36: speaker_data/train_data/wavfiles/Speaker_0014/Speaker_0014_00008.wav\n",
            "Analyzing file 8 of 36: speaker_data/train_data/wavfiles/Speaker_0014/Speaker_0014_00009.wav\n",
            "Analyzing file 9 of 36: speaker_data/train_data/wavfiles/Speaker_0014/Speaker_0014_00011.wav\n",
            "Analyzing file 10 of 36: speaker_data/train_data/wavfiles/Speaker_0014/Speaker_0014_00013.wav\n",
            "Analyzing file 11 of 36: speaker_data/train_data/wavfiles/Speaker_0014/Speaker_0014_00014.wav\n",
            "Analyzing file 12 of 36: speaker_data/train_data/wavfiles/Speaker_0014/Speaker_0014_00016.wav\n",
            "Analyzing file 13 of 36: speaker_data/train_data/wavfiles/Speaker_0014/Speaker_0014_00017.wav\n",
            "Analyzing file 14 of 36: speaker_data/train_data/wavfiles/Speaker_0014/Speaker_0014_00020.wav\n",
            "Analyzing file 15 of 36: speaker_data/train_data/wavfiles/Speaker_0014/Speaker_0014_00021.wav\n",
            "Analyzing file 16 of 36: speaker_data/train_data/wavfiles/Speaker_0014/Speaker_0014_00023.wav\n",
            "Analyzing file 17 of 36: speaker_data/train_data/wavfiles/Speaker_0014/Speaker_0014_00024.wav\n",
            "Analyzing file 18 of 36: speaker_data/train_data/wavfiles/Speaker_0014/Speaker_0014_00025.wav\n",
            "Analyzing file 19 of 36: speaker_data/train_data/wavfiles/Speaker_0014/Speaker_0014_00026.wav\n",
            "Analyzing file 20 of 36: speaker_data/train_data/wavfiles/Speaker_0014/Speaker_0014_00028.wav\n",
            "Analyzing file 21 of 36: speaker_data/train_data/wavfiles/Speaker_0014/Speaker_0014_00030.wav\n",
            "Analyzing file 22 of 36: speaker_data/train_data/wavfiles/Speaker_0014/Speaker_0014_00031.wav\n",
            "Analyzing file 23 of 36: speaker_data/train_data/wavfiles/Speaker_0014/Speaker_0014_00032.wav\n",
            "Analyzing file 24 of 36: speaker_data/train_data/wavfiles/Speaker_0014/Speaker_0014_00033.wav\n",
            "Analyzing file 25 of 36: speaker_data/train_data/wavfiles/Speaker_0014/Speaker_0014_00034.wav\n",
            "Analyzing file 26 of 36: speaker_data/train_data/wavfiles/Speaker_0014/Speaker_0014_00036.wav\n",
            "Analyzing file 27 of 36: speaker_data/train_data/wavfiles/Speaker_0014/Speaker_0014_00038.wav\n",
            "Analyzing file 28 of 36: speaker_data/train_data/wavfiles/Speaker_0014/Speaker_0014_00039.wav\n",
            "Analyzing file 29 of 36: speaker_data/train_data/wavfiles/Speaker_0014/Speaker_0014_00040.wav\n",
            "Analyzing file 30 of 36: speaker_data/train_data/wavfiles/Speaker_0014/Speaker_0014_00041.wav\n",
            "Analyzing file 31 of 36: speaker_data/train_data/wavfiles/Speaker_0014/Speaker_0014_00043.wav\n",
            "Analyzing file 32 of 36: speaker_data/train_data/wavfiles/Speaker_0014/Speaker_0014_00044.wav\n",
            "Analyzing file 33 of 36: speaker_data/train_data/wavfiles/Speaker_0014/Speaker_0014_00046.wav\n",
            "Analyzing file 34 of 36: speaker_data/train_data/wavfiles/Speaker_0014/Speaker_0014_00047.wav\n",
            "Analyzing file 35 of 36: speaker_data/train_data/wavfiles/Speaker_0014/Speaker_0014_00048.wav\n",
            "Analyzing file 36 of 36: speaker_data/train_data/wavfiles/Speaker_0014/Speaker_0014_00049.wav\n",
            "Feature extraction complexity ratio: 35.6 x realtime\n",
            "Speaker0037\n",
            "Analyzing file 1 of 39: speaker_data/train_data/wavfiles/Speaker0037/Speaker0037_000.wav\n",
            "Analyzing file 2 of 39: speaker_data/train_data/wavfiles/Speaker0037/Speaker0037_001.wav\n",
            "Analyzing file 3 of 39: speaker_data/train_data/wavfiles/Speaker0037/Speaker0037_002.wav\n",
            "Analyzing file 4 of 39: speaker_data/train_data/wavfiles/Speaker0037/Speaker0037_004.wav\n",
            "Analyzing file 5 of 39: speaker_data/train_data/wavfiles/Speaker0037/Speaker0037_005.wav\n",
            "Analyzing file 6 of 39: speaker_data/train_data/wavfiles/Speaker0037/Speaker0037_007.wav\n",
            "Analyzing file 7 of 39: speaker_data/train_data/wavfiles/Speaker0037/Speaker0037_008.wav\n",
            "Analyzing file 8 of 39: speaker_data/train_data/wavfiles/Speaker0037/Speaker0037_011.wav\n",
            "Analyzing file 9 of 39: speaker_data/train_data/wavfiles/Speaker0037/Speaker0037_012.wav\n",
            "Analyzing file 10 of 39: speaker_data/train_data/wavfiles/Speaker0037/Speaker0037_014.wav\n",
            "Analyzing file 11 of 39: speaker_data/train_data/wavfiles/Speaker0037/Speaker0037_016.wav\n",
            "Analyzing file 12 of 39: speaker_data/train_data/wavfiles/Speaker0037/Speaker0037_022.wav\n",
            "Analyzing file 13 of 39: speaker_data/train_data/wavfiles/Speaker0037/Speaker0037_023.wav\n",
            "Analyzing file 14 of 39: speaker_data/train_data/wavfiles/Speaker0037/Speaker0037_024.wav\n",
            "Analyzing file 15 of 39: speaker_data/train_data/wavfiles/Speaker0037/Speaker0037_026.wav\n",
            "Analyzing file 16 of 39: speaker_data/train_data/wavfiles/Speaker0037/Speaker0037_027.wav\n",
            "Analyzing file 17 of 39: speaker_data/train_data/wavfiles/Speaker0037/Speaker0037_030.wav\n",
            "Analyzing file 18 of 39: speaker_data/train_data/wavfiles/Speaker0037/Speaker0037_031.wav\n",
            "Analyzing file 19 of 39: speaker_data/train_data/wavfiles/Speaker0037/Speaker0037_032.wav\n",
            "Analyzing file 20 of 39: speaker_data/train_data/wavfiles/Speaker0037/Speaker0037_033.wav\n",
            "Analyzing file 21 of 39: speaker_data/train_data/wavfiles/Speaker0037/Speaker0037_036.wav\n",
            "Analyzing file 22 of 39: speaker_data/train_data/wavfiles/Speaker0037/Speaker0037_037.wav\n",
            "Analyzing file 23 of 39: speaker_data/train_data/wavfiles/Speaker0037/Speaker0037_038.wav\n",
            "Analyzing file 24 of 39: speaker_data/train_data/wavfiles/Speaker0037/Speaker0037_039.wav\n",
            "Analyzing file 25 of 39: speaker_data/train_data/wavfiles/Speaker0037/Speaker0037_040.wav\n",
            "Analyzing file 26 of 39: speaker_data/train_data/wavfiles/Speaker0037/Speaker0037_041.wav\n",
            "Analyzing file 27 of 39: speaker_data/train_data/wavfiles/Speaker0037/Speaker0037_042.wav\n",
            "Analyzing file 28 of 39: speaker_data/train_data/wavfiles/Speaker0037/Speaker0037_043.wav\n",
            "Analyzing file 29 of 39: speaker_data/train_data/wavfiles/Speaker0037/Speaker0037_044.wav\n",
            "Analyzing file 30 of 39: speaker_data/train_data/wavfiles/Speaker0037/Speaker0037_045.wav\n",
            "Analyzing file 31 of 39: speaker_data/train_data/wavfiles/Speaker0037/Speaker0037_046.wav\n",
            "Analyzing file 32 of 39: speaker_data/train_data/wavfiles/Speaker0037/Speaker0037_047.wav\n",
            "Analyzing file 33 of 39: speaker_data/train_data/wavfiles/Speaker0037/Speaker0037_048.wav\n",
            "Analyzing file 34 of 39: speaker_data/train_data/wavfiles/Speaker0037/Speaker0037_049.wav\n",
            "Analyzing file 35 of 39: speaker_data/train_data/wavfiles/Speaker0037/Speaker0037_050.wav\n",
            "Analyzing file 36 of 39: speaker_data/train_data/wavfiles/Speaker0037/Speaker0037_051.wav\n",
            "Analyzing file 37 of 39: speaker_data/train_data/wavfiles/Speaker0037/Speaker0037_052.wav\n",
            "Analyzing file 38 of 39: speaker_data/train_data/wavfiles/Speaker0037/Speaker0037_053.wav\n",
            "Analyzing file 39 of 39: speaker_data/train_data/wavfiles/Speaker0037/Speaker0037_054.wav\n",
            "Feature extraction complexity ratio: 31.4 x realtime\n",
            "Speaker_0021\n",
            "Analyzing file 1 of 41: speaker_data/train_data/wavfiles/Speaker_0021/Speaker_0021_00000.wav\n",
            "Analyzing file 2 of 41: speaker_data/train_data/wavfiles/Speaker_0021/Speaker_0021_00002.wav\n",
            "Analyzing file 3 of 41: speaker_data/train_data/wavfiles/Speaker_0021/Speaker_0021_00003.wav\n",
            "Analyzing file 4 of 41: speaker_data/train_data/wavfiles/Speaker_0021/Speaker_0021_00004.wav\n",
            "Analyzing file 5 of 41: speaker_data/train_data/wavfiles/Speaker_0021/Speaker_0021_00005.wav\n",
            "Analyzing file 6 of 41: speaker_data/train_data/wavfiles/Speaker_0021/Speaker_0021_00006.wav\n",
            "Analyzing file 7 of 41: speaker_data/train_data/wavfiles/Speaker_0021/Speaker_0021_00007.wav\n",
            "Analyzing file 8 of 41: speaker_data/train_data/wavfiles/Speaker_0021/Speaker_0021_00008.wav\n",
            "Analyzing file 9 of 41: speaker_data/train_data/wavfiles/Speaker_0021/Speaker_0021_00012.wav\n",
            "Analyzing file 10 of 41: speaker_data/train_data/wavfiles/Speaker_0021/Speaker_0021_00013.wav\n",
            "Analyzing file 11 of 41: speaker_data/train_data/wavfiles/Speaker_0021/Speaker_0021_00017.wav\n",
            "Analyzing file 12 of 41: speaker_data/train_data/wavfiles/Speaker_0021/Speaker_0021_00018.wav\n",
            "Analyzing file 13 of 41: speaker_data/train_data/wavfiles/Speaker_0021/Speaker_0021_00019.wav\n",
            "Analyzing file 14 of 41: speaker_data/train_data/wavfiles/Speaker_0021/Speaker_0021_00021.wav\n",
            "Analyzing file 15 of 41: speaker_data/train_data/wavfiles/Speaker_0021/Speaker_0021_00022.wav\n",
            "Analyzing file 16 of 41: speaker_data/train_data/wavfiles/Speaker_0021/Speaker_0021_00024.wav\n",
            "Analyzing file 17 of 41: speaker_data/train_data/wavfiles/Speaker_0021/Speaker_0021_00026.wav\n",
            "Analyzing file 18 of 41: speaker_data/train_data/wavfiles/Speaker_0021/Speaker_0021_00027.wav\n",
            "Analyzing file 19 of 41: speaker_data/train_data/wavfiles/Speaker_0021/Speaker_0021_00028.wav\n",
            "Analyzing file 20 of 41: speaker_data/train_data/wavfiles/Speaker_0021/Speaker_0021_00030.wav\n",
            "Analyzing file 21 of 41: speaker_data/train_data/wavfiles/Speaker_0021/Speaker_0021_00031.wav\n",
            "Analyzing file 22 of 41: speaker_data/train_data/wavfiles/Speaker_0021/Speaker_0021_00033.wav\n",
            "Analyzing file 23 of 41: speaker_data/train_data/wavfiles/Speaker_0021/Speaker_0021_00034.wav\n",
            "Analyzing file 24 of 41: speaker_data/train_data/wavfiles/Speaker_0021/Speaker_0021_00035.wav\n",
            "Analyzing file 25 of 41: speaker_data/train_data/wavfiles/Speaker_0021/Speaker_0021_00036.wav\n",
            "Analyzing file 26 of 41: speaker_data/train_data/wavfiles/Speaker_0021/Speaker_0021_00037.wav\n",
            "Analyzing file 27 of 41: speaker_data/train_data/wavfiles/Speaker_0021/Speaker_0021_00041.wav\n",
            "Analyzing file 28 of 41: speaker_data/train_data/wavfiles/Speaker_0021/Speaker_0021_00042.wav\n",
            "Analyzing file 29 of 41: speaker_data/train_data/wavfiles/Speaker_0021/Speaker_0021_00043.wav\n",
            "Analyzing file 30 of 41: speaker_data/train_data/wavfiles/Speaker_0021/Speaker_0021_00044.wav\n",
            "Analyzing file 31 of 41: speaker_data/train_data/wavfiles/Speaker_0021/Speaker_0021_00045.wav\n",
            "Analyzing file 32 of 41: speaker_data/train_data/wavfiles/Speaker_0021/Speaker_0021_00046.wav\n",
            "Analyzing file 33 of 41: speaker_data/train_data/wavfiles/Speaker_0021/Speaker_0021_00048.wav\n",
            "Analyzing file 34 of 41: speaker_data/train_data/wavfiles/Speaker_0021/Speaker_0021_00049.wav\n",
            "Analyzing file 35 of 41: speaker_data/train_data/wavfiles/Speaker_0021/Speaker_0021_00050.wav\n",
            "Analyzing file 36 of 41: speaker_data/train_data/wavfiles/Speaker_0021/Speaker_0021_00051.wav\n",
            "Analyzing file 37 of 41: speaker_data/train_data/wavfiles/Speaker_0021/Speaker_0021_00052.wav\n",
            "Analyzing file 38 of 41: speaker_data/train_data/wavfiles/Speaker_0021/Speaker_0021_00053.wav\n",
            "Analyzing file 39 of 41: speaker_data/train_data/wavfiles/Speaker_0021/Speaker_0021_00054.wav\n",
            "Analyzing file 40 of 41: speaker_data/train_data/wavfiles/Speaker_0021/Speaker_0021_00055.wav\n",
            "Analyzing file 41 of 41: speaker_data/train_data/wavfiles/Speaker_0021/Speaker_0021_00056.wav\n",
            "Feature extraction complexity ratio: 34.8 x realtime\n",
            "Speaker0035\n",
            "Analyzing file 1 of 23: speaker_data/train_data/wavfiles/Speaker0035/Speaker0035_000.wav\n",
            "Analyzing file 2 of 23: speaker_data/train_data/wavfiles/Speaker0035/Speaker0035_001.wav\n",
            "Analyzing file 3 of 23: speaker_data/train_data/wavfiles/Speaker0035/Speaker0035_003.wav\n",
            "Analyzing file 4 of 23: speaker_data/train_data/wavfiles/Speaker0035/Speaker0035_004.wav\n",
            "Analyzing file 5 of 23: speaker_data/train_data/wavfiles/Speaker0035/Speaker0035_006.wav\n",
            "Analyzing file 6 of 23: speaker_data/train_data/wavfiles/Speaker0035/Speaker0035_007.wav\n",
            "Analyzing file 7 of 23: speaker_data/train_data/wavfiles/Speaker0035/Speaker0035_008.wav\n",
            "Analyzing file 8 of 23: speaker_data/train_data/wavfiles/Speaker0035/Speaker0035_010.wav\n",
            "Analyzing file 9 of 23: speaker_data/train_data/wavfiles/Speaker0035/Speaker0035_011.wav\n",
            "Analyzing file 10 of 23: speaker_data/train_data/wavfiles/Speaker0035/Speaker0035_012.wav\n",
            "Analyzing file 11 of 23: speaker_data/train_data/wavfiles/Speaker0035/Speaker0035_013.wav\n",
            "Analyzing file 12 of 23: speaker_data/train_data/wavfiles/Speaker0035/Speaker0035_014.wav\n",
            "Analyzing file 13 of 23: speaker_data/train_data/wavfiles/Speaker0035/Speaker0035_016.wav\n",
            "Analyzing file 14 of 23: speaker_data/train_data/wavfiles/Speaker0035/Speaker0035_017.wav\n",
            "Analyzing file 15 of 23: speaker_data/train_data/wavfiles/Speaker0035/Speaker0035_018.wav\n",
            "Analyzing file 16 of 23: speaker_data/train_data/wavfiles/Speaker0035/Speaker0035_019.wav\n",
            "Analyzing file 17 of 23: speaker_data/train_data/wavfiles/Speaker0035/Speaker0035_020.wav\n",
            "Analyzing file 18 of 23: speaker_data/train_data/wavfiles/Speaker0035/Speaker0035_022.wav\n",
            "Analyzing file 19 of 23: speaker_data/train_data/wavfiles/Speaker0035/Speaker0035_023.wav\n",
            "Analyzing file 20 of 23: speaker_data/train_data/wavfiles/Speaker0035/Speaker0035_025.wav\n",
            "Analyzing file 21 of 23: speaker_data/train_data/wavfiles/Speaker0035/Speaker0035_029.wav\n",
            "Analyzing file 22 of 23: speaker_data/train_data/wavfiles/Speaker0035/Speaker0035_030.wav\n",
            "Analyzing file 23 of 23: speaker_data/train_data/wavfiles/Speaker0035/Speaker0035_031.wav\n",
            "Feature extraction complexity ratio: 31.0 x realtime\n",
            "Speaker0042\n",
            "Analyzing file 1 of 29: speaker_data/train_data/wavfiles/Speaker0042/Speaker0042_000.wav\n",
            "Analyzing file 2 of 29: speaker_data/train_data/wavfiles/Speaker0042/Speaker0042_001.wav\n",
            "Analyzing file 3 of 29: speaker_data/train_data/wavfiles/Speaker0042/Speaker0042_004.wav\n",
            "Analyzing file 4 of 29: speaker_data/train_data/wavfiles/Speaker0042/Speaker0042_005.wav\n",
            "Analyzing file 5 of 29: speaker_data/train_data/wavfiles/Speaker0042/Speaker0042_006.wav\n",
            "Analyzing file 6 of 29: speaker_data/train_data/wavfiles/Speaker0042/Speaker0042_007.wav\n",
            "Analyzing file 7 of 29: speaker_data/train_data/wavfiles/Speaker0042/Speaker0042_008.wav\n",
            "Analyzing file 8 of 29: speaker_data/train_data/wavfiles/Speaker0042/Speaker0042_009.wav\n",
            "Analyzing file 9 of 29: speaker_data/train_data/wavfiles/Speaker0042/Speaker0042_010.wav\n",
            "Analyzing file 10 of 29: speaker_data/train_data/wavfiles/Speaker0042/Speaker0042_015.wav\n",
            "Analyzing file 11 of 29: speaker_data/train_data/wavfiles/Speaker0042/Speaker0042_016.wav\n",
            "Analyzing file 12 of 29: speaker_data/train_data/wavfiles/Speaker0042/Speaker0042_019.wav\n",
            "Analyzing file 13 of 29: speaker_data/train_data/wavfiles/Speaker0042/Speaker0042_021.wav\n",
            "Analyzing file 14 of 29: speaker_data/train_data/wavfiles/Speaker0042/Speaker0042_022.wav\n",
            "Analyzing file 15 of 29: speaker_data/train_data/wavfiles/Speaker0042/Speaker0042_024.wav\n",
            "Analyzing file 16 of 29: speaker_data/train_data/wavfiles/Speaker0042/Speaker0042_025.wav\n",
            "Analyzing file 17 of 29: speaker_data/train_data/wavfiles/Speaker0042/Speaker0042_027.wav\n",
            "Analyzing file 18 of 29: speaker_data/train_data/wavfiles/Speaker0042/Speaker0042_028.wav\n",
            "Analyzing file 19 of 29: speaker_data/train_data/wavfiles/Speaker0042/Speaker0042_029.wav\n",
            "Analyzing file 20 of 29: speaker_data/train_data/wavfiles/Speaker0042/Speaker0042_030.wav\n",
            "Analyzing file 21 of 29: speaker_data/train_data/wavfiles/Speaker0042/Speaker0042_031.wav\n",
            "Analyzing file 22 of 29: speaker_data/train_data/wavfiles/Speaker0042/Speaker0042_032.wav\n",
            "Analyzing file 23 of 29: speaker_data/train_data/wavfiles/Speaker0042/Speaker0042_034.wav\n",
            "Analyzing file 24 of 29: speaker_data/train_data/wavfiles/Speaker0042/Speaker0042_035.wav\n",
            "Analyzing file 25 of 29: speaker_data/train_data/wavfiles/Speaker0042/Speaker0042_036.wav\n",
            "Analyzing file 26 of 29: speaker_data/train_data/wavfiles/Speaker0042/Speaker0042_037.wav\n",
            "Analyzing file 27 of 29: speaker_data/train_data/wavfiles/Speaker0042/Speaker0042_038.wav\n",
            "Analyzing file 28 of 29: speaker_data/train_data/wavfiles/Speaker0042/Speaker0042_039.wav\n",
            "Analyzing file 29 of 29: speaker_data/train_data/wavfiles/Speaker0042/Speaker0042_040.wav\n",
            "Feature extraction complexity ratio: 30.9 x realtime\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlzwpPhf1qyp"
      },
      "source": [
        "> Once we have all the pickle files with extracted features, we can generate the X,y for our machine learning algorithms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeIr2fadqiMn"
      },
      "source": [
        "def get_X_y(tr_dir):\n",
        "\n",
        "  '''\n",
        "  This function fetches the features and label from the pickle files created previously\n",
        "\n",
        "  ARGS: \n",
        "    - tr_dir: Target directory under which train, test folders are present\n",
        "\n",
        "  RETURNS:\n",
        "    - X: A numpy array of all the features\n",
        "    - y: A numpy array of all corresponding labels\n",
        "\n",
        "  '''\n",
        "  # Fetch each file, store the features in array X and label in y\n",
        "  X,y = [],[]\n",
        "  for lbl in os.listdir(f\"{tr_dir}/train_data/features\"):\n",
        "    for f in os.listdir(f\"{tr_dir}/train_data/features/{lbl}\"):\n",
        "      fn, lb = joblib.load(f\"{tr_dir}/train_data/features/{lbl}/{f}\")\n",
        "      X.append(fn)\n",
        "      y.append(lb)\n",
        "  \n",
        "  # Converting the arrays to numpy arrays for better computational efficiency in machine learning\n",
        "  X = np.array(X)\n",
        "  y = np.array(y)\n",
        "\n",
        "  return X,y"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4F7UuWFQ4ZjC"
      },
      "source": [
        "X, y = get_X_y(tr_dir)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "herryqqD2Mvp"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YR-4W1Zi2V75"
      },
      "source": [
        "\n",
        "\n",
        "> For this project we are using SVM, KNN and Random Forest Classifier to train the model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYIO2j0HK1VG"
      },
      "source": [
        "> We will be using the GridSearchCV lib to determine the best parameters for model specified. \n",
        "> We are also using Cross Validation to split the train data into train and validation data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUlWMI20UCk4"
      },
      "source": [
        "def train_model(X,y,model='svm',cv=5):\n",
        "  '''\n",
        "  This function will perform training on the dataset and return the trained model.\n",
        "  Currently the parameters for each trainer are hard-coded but can be modified.\n",
        "\n",
        "  ARGS:\n",
        "    - X,y:   The featrues and labels\n",
        "    - model: The classifier to be used (svm, knn, random forest)\n",
        "    - cv:    Cross Validation Folds\n",
        "\n",
        "  '''\n",
        "  params = {}\n",
        "\n",
        "  ###### SVM MODEL #########\n",
        "  if model == 'svm':\n",
        "    \n",
        "    svc = SVC()\n",
        "    \n",
        "    params = {\n",
        "    'C' : [0.001,0.01,0.1,10,100],\n",
        "    'kernel' : ['rbf', 'linear', 'poly', 'sigmoid']\n",
        "    }\n",
        "\n",
        "    svc_grid = GridSearchCV(svc,params,cv=cv)\n",
        "\n",
        "    svc_grid.fit(X,y)\n",
        "\n",
        "    print(f\"SVC Best Accuracy: {svc_grid.best_score_}\")\n",
        "    print(f\"SVC Best Estimator: {svc_grid.best_estimator_}\")\n",
        "\n",
        "    return svc_grid\n",
        "  \n",
        "  ###### KNN MODEL #########\n",
        "  if model == 'knn':\n",
        "\n",
        "    knn = KNeighborsClassifier()\n",
        "\n",
        "    params = {\n",
        "        'n_neighbors': [3, 6, 12, 15]\n",
        "    }\n",
        "\n",
        "    knn_grid = GridSearchCV(knn,params,cv=cv)\n",
        "\n",
        "    knn_grid.fit(X,y)\n",
        "\n",
        "    print(f\"KNN Best Accuracy: {knn_grid.best_score_}\")\n",
        "    print(f\"KNN Best Estimator: {knn_grid.best_estimator_}\")\n",
        "\n",
        "    return knn_grid\n",
        "    \n",
        "  ###### RANDOM FOREST MODEL #########  \n",
        "  if model == 'rf':\n",
        "\n",
        "    rf = RandomForestClassifier()\n",
        "\n",
        "    params = {\n",
        "        'n_estimators': [100, 200, 400, 600]\n",
        "    }\n",
        "\n",
        "    rf_grid = GridSearchCV(rf,params,cv=cv)\n",
        "\n",
        "    rf_grid.fit(X,y)\n",
        "\n",
        "    print(f\"Random Forest Best Accuracy: {rf_grid.best_score_}\")\n",
        "    print(f\"Random Best Estimator: {rf_grid.best_estimator_}\")\n",
        "    \n",
        "    return rf_grid"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjV-5Hwmg7sN",
        "outputId": "260cd084-4573-4ffb-a097-1068f504da7e"
      },
      "source": [
        "svm = train_model(X,y)\n",
        "knn = train_model(X,y,model='knn')\n",
        "rf = train_model(X,y,model='rf')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVC Best Accuracy: 0.9916666666666666\n",
            "SVC Best Estimator: SVC(C=10, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False)\n",
            "KNN Best Accuracy: 0.9833333333333332\n",
            "KNN Best Estimator: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
            "                     weights='uniform')\n",
            "Random Forest Best Accuracy: 0.9958333333333333\n",
            "Random Best Estimator: RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpCxl9JLLRWe"
      },
      "source": [
        "### Saving the model using SQLite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tq5CUj0jLe-z"
      },
      "source": [
        "> For the purpose of this project, we are using the SQLite libraries to save our models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxZ-Aj23eSmR"
      },
      "source": [
        "def createTrainTable():\n",
        "\n",
        "  '''\n",
        "  This function will create the database and create the table in which we need to\n",
        "  persist the models.\n",
        "\n",
        "  DATABASE NAME = Voice_Models\n",
        "  TABLE NAME = trained_models\n",
        "\n",
        "  '''\n",
        "  \n",
        "  try:\n",
        "        sqliteConnection = sqlite3.connect('Voice_Models.db')\n",
        "        cursor = sqliteConnection.cursor()\n",
        "        print(\"Connected to SQLite\")\n",
        "        create_query = \"\"\"CREATE TABLE IF NOT EXISTS trained_models\n",
        "                          (id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "                           model_name TEXT NOT NULL UNIQUE,\n",
        "                           model BLOB NOT NULL,\n",
        "                           accuracy REAL NOT NULL UNIQUE,\n",
        "                           date TEXT NOT NULL)\"\"\";\n",
        "        cursor.execute(create_query)\n",
        "        sqliteConnection.commit()\n",
        "        print(\"SQLite table created\")\n",
        "\n",
        "        cursor.close()\n",
        "\n",
        "  except sqlite3.Error as error:\n",
        "    print(\"Error while creating a sqlite table\", error)\n",
        "  finally:\n",
        "    if sqliteConnection:\n",
        "      sqliteConnection.close()\n",
        "      print(\"sqlite connection is closed\")\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xwch6cveVAC",
        "outputId": "7b90c850-68b6-454f-e718-6f1f67c19700"
      },
      "source": [
        "createTrainTable()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Connected to SQLite\n",
            "SQLite table created\n",
            "sqlite connection is closed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-MbqobDMQCu"
      },
      "source": [
        "> A small function to save the model as file and the convert it to a blob that can be stored in the database"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSkw7XdWYGH7"
      },
      "source": [
        "def convertBinary(model,model_name):\n",
        "  \n",
        "  blobData = ''\n",
        "  \n",
        "  joblib.dump(model,f\"{model_name}.pkl\")\n",
        "  \n",
        "  with open(f\"{model_name}.pkl\", 'rb') as file:\n",
        "    blobData = file.read()\n",
        "  \n",
        "  os.system(f\"rm -f {model_name}.pkl\")\n",
        "\n",
        "  return blobData"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBqB7wqXOvcp"
      },
      "source": [
        "> Inserting the model in the database"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYfuju_Xbs1x"
      },
      "source": [
        "def insertModel(model_name,model):\n",
        "  \n",
        "  '''\n",
        "  This function will insert the model specified into the trained_model table.\n",
        "  The following details will be saved: \n",
        "   - model_name = The name of the model.\n",
        "   - model = The model which we need to insert\n",
        "   - accuracy = The best_score attribute of the model\n",
        "   - date = Current date and time\n",
        "\n",
        "  '''\n",
        "  try:\n",
        "      sqliteConnection = sqlite3.connect('Voice_Models.db')\n",
        "      cursor = sqliteConnection.cursor()\n",
        "      print(\"Connected to SQLite\")\n",
        "      \n",
        "      insert_query = \"\"\" INSERT INTO trained_models\n",
        "                                (model_name, model, accuracy, date) VALUES (?, ?, ?, ?)\"\"\"\n",
        "\n",
        "      accuracy = model.best_score_\n",
        "      # Calling the function to save the model in file and return the converted blob\n",
        "      model_blob = convertBinary(model,model_name)\n",
        "      \n",
        "      data_tuple = (model_name, model_blob, accuracy,datetime.datetime.now())\n",
        "      cursor.execute(insert_query, data_tuple)\n",
        "      sqliteConnection.commit()\n",
        "      print(\"Successfully Inserted\")\n",
        "      cursor.close()\n",
        "\n",
        "  except sqlite3.Error as error:\n",
        "      print(\"Failed to insert blob data into sqlite table\", error)\n",
        "  finally:\n",
        "      if sqliteConnection:\n",
        "          sqliteConnection.close()\n",
        "          print(\"the sqlite connection is closed\")\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVYKuStTgyUg",
        "outputId": "7d7ec846-8e33-49f8-c5fa-26100c7cb10b"
      },
      "source": [
        "insertModel('svm',svm)\n",
        "insertModel('knn',knn)\n",
        "insertModel('rf',rf)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Connected to SQLite\n",
            "Successfully Inserted\n",
            "the sqlite connection is closed\n",
            "Connected to SQLite\n",
            "Successfully Inserted\n",
            "the sqlite connection is closed\n",
            "Connected to SQLite\n",
            "Successfully Inserted\n",
            "the sqlite connection is closed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkzoeP0hPwsH"
      },
      "source": [
        "> A function to write the blob to file from which the model can be loaded"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbgEU3EHdr2o"
      },
      "source": [
        "def writeTofile(data, filename):\n",
        "  '''\n",
        "  This function will take the model and a filename and write the blob data into\n",
        "  the file\n",
        "  '''\n",
        "    # Convert binary data to proper format and write it on Hard Disk\n",
        "  with open(f\"{filename}.pkl\", 'wb') as file:\n",
        "      file.write(data)\n",
        "  print(\"Stored blob data into: \", filename, \"\\n\")\n",
        "  return f\"{filename}.pkl\""
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGqhxOAKdy_L"
      },
      "source": [
        "def readBlobData(model_name):\n",
        "  '''\n",
        "  This function fetch the model that was saved with the model name specified.\n",
        "\n",
        "  ARG: model_name - the name of the model to be fetched\n",
        "  RETURNS: Filename of the file created with the model\n",
        "  '''\n",
        "  try:\n",
        "      sqliteConnection = sqlite3.connect('Voice_Models.db')\n",
        "      cursor = sqliteConnection.cursor()\n",
        "      print(\"Connected to SQLite\")\n",
        "\n",
        "      model_query = \"\"\"SELECT * from trained_models where model_name = ? order by date desc limit 1\"\"\"\n",
        "      cursor.execute(model_query, (model_name,))\n",
        "      record = cursor.fetchall()\n",
        "      for row in record:\n",
        "          #print(\"Id = \", row[0], \"Name = \", row[1])\n",
        "          model_name = row[1]\n",
        "          model = row[2]\n",
        "          accuracy = row[3]\n",
        "          lastModified = row[4]\n",
        "\n",
        "          filename = writeTofile(model, model_name)\n",
        "          \n",
        "      cursor.close()\n",
        "\n",
        "  except sqlite3.Error as error:\n",
        "      print(\"Failed to read blob data from sqlite table\", error)\n",
        "  finally:\n",
        "      if sqliteConnection:\n",
        "          sqliteConnection.close()\n",
        "          print(\"sqlite connection is closed\")\n",
        "\n",
        "  return filename"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sy-hMtjNhqXX",
        "outputId": "31b1ceea-78c8-442b-ebe1-87ca9b5b144d"
      },
      "source": [
        "# Getting the model\n",
        "loaded_svm = joblib.load(readBlobData('svm'))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Connected to SQLite\n",
            "Stored blob data into:  svm \n",
            "\n",
            "sqlite connection is closed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngdl8Owvi-bv",
        "outputId": "096a1ce2-57c8-4cfd-fe5d-c6947cc918d7"
      },
      "source": [
        "print(svm)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GridSearchCV(cv=5, error_score=nan,\n",
            "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
            "                           class_weight=None, coef0=0.0,\n",
            "                           decision_function_shape='ovr', degree=3,\n",
            "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
            "                           probability=False, random_state=None, shrinking=True,\n",
            "                           tol=0.001, verbose=False),\n",
            "             iid='deprecated', n_jobs=None,\n",
            "             param_grid={'C': [0.001, 0.01, 0.1, 10, 100],\n",
            "                         'kernel': ['rbf', 'linear', 'poly', 'sigmoid']},\n",
            "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
            "             scoring=None, verbose=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLUQHol3kLcS",
        "outputId": "7697e2d1-f27b-47a0-b052-f53604e3d561"
      },
      "source": [
        "svm.best_estimator_"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=10, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkYG1zmtSRf_"
      },
      "source": [
        "### Evaluating the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGr4qBOlSs86"
      },
      "source": [
        "> We can now proceed to see how our model performs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SStyvTBbBoDx"
      },
      "source": [
        "def predict_speaker(test_file,model,mid_window=1,mid_step=1,\n",
        "                    short_window=0.05,short_step=0.05):\n",
        "  '''\n",
        "  This function will take the audio file in the wav format and process it to \n",
        "  extract the features. \n",
        "  Then the model will predict the speaker based on the features and return the \n",
        "  predicted value\n",
        "  '''\n",
        "\n",
        "  fs, s = audioBasicIO.read_audio_file(test_file)\n",
        "\n",
        "  mid_features,short_features,_ = aT.mid_feature_extraction(s, fs, mid_window * fs,\n",
        "                                          mid_step * fs ,\n",
        "                                          short_window * fs,\n",
        "                                          short_step * fs)\n",
        "\n",
        "  # The midterm features returned will be for each window, we need to average \n",
        "  # out the features and reshape it to have the desired shape.\n",
        "  mid_features = mid_features.mean(axis=1).reshape(1,-1)\n",
        "\n",
        "  pred = model.predict(mid_features)\n",
        "\n",
        "  return pred[0]"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2-wNJlxUNVf"
      },
      "source": [
        "> Testing our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHwH0AXxJ51R"
      },
      "source": [
        "y, y_pred = [],[]\n",
        "for speaker in os.listdir(f\"{tr_dir}/test_data/\"):\n",
        "  for f in os.listdir(f\"{tr_dir}/test_data/{speaker}\"):\n",
        "    \n",
        "    #print()\n",
        "    pred = predict_speaker(f\"{tr_dir}/test_data/{speaker}/{f}\",svm)\n",
        "    y.append(speaker)\n",
        "    y_pred.append(pred)\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfhUn5WeUap_"
      },
      "source": [
        "> Viewing the results in a classification report and a confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWaQiu0pMkvY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "497f6430-995d-4d89-cb0d-73e453685087"
      },
      "source": [
        "print(classification_report(y,y_pred))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            " Speaker0029       1.00      0.89      0.94         9\n",
            " Speaker0035       1.00      1.00      1.00         9\n",
            " Speaker0037       0.89      1.00      0.94        16\n",
            " Speaker0042       1.00      1.00      1.00        12\n",
            "Speaker_0005       1.00      1.00      1.00        21\n",
            "Speaker_0014       1.00      1.00      1.00        15\n",
            "Speaker_0021       1.00      0.94      0.97        17\n",
            "\n",
            "    accuracy                           0.98        99\n",
            "   macro avg       0.98      0.98      0.98        99\n",
            "weighted avg       0.98      0.98      0.98        99\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUhxcqiAMpdZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d05ab479-f198-455c-8331-d63eea103c43"
      },
      "source": [
        "print(confusion_matrix(y,y_pred))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 8  0  1  0  0  0  0]\n",
            " [ 0  9  0  0  0  0  0]\n",
            " [ 0  0 16  0  0  0  0]\n",
            " [ 0  0  0 12  0  0  0]\n",
            " [ 0  0  0  0 21  0  0]\n",
            " [ 0  0  0  0  0 15  0]\n",
            " [ 0  0  1  0  0  0 16]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9IP_lzF6NRh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}